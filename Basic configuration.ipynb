{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9310a0f0-1ba5-462a-ac0d-9ac2d72677b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Basic configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d50439a9-7121-453c-a44c-311df6c8b584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Credentials for Azure SQL database (using Azure Key Vault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7142dda-22fe-4bab-94ae-0a91fc69c3c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_db_retail_key = dbutils.secrets.get(scope=\"keys\", key=\"sqldbretailkey\")\n",
    "sql_db_retail_url = \"jdbc:sqlserver://retail-oltp-server.database.windows.net:1433;databaseName=retail\"\n",
    "sql_db_retail_user = \"andre\"\n",
    "\n",
    "spark.conf.set(\"spark.sql.retail_url\", sql_db_retail_url)\n",
    "spark.conf.set(\"spark.sql.retail_user\", sql_db_retail_user)\n",
    "spark.conf.set(\"spark.sql.retail_key\", sql_db_retail_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "361aab00-f585-4eb2-83dd-dc8b2f766576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Credentials for mounting (using Azure Key Vault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5789a30-d672-47d9-afab-aa9764ee493d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For accessing the storage accounting\n",
    "storage_account_key= dbutils.secrets.get(scope=\"keys\", key=\"storageaccountkey\")\n",
    "mount_point = \"/mnt/storageforretail/container\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b35f6d63-0368-4e14-9adf-fa323b52213b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66175260-b233-4476-b0ce-f8e878c329f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuring my local time zone\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"America/Sao_Paulo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a5fc0a-f740-44de-9061-11e126a858f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining the credentials of Azure SQL database\n",
    "\n",
    "sql_db_retail_key = \"@ndr3!1234\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bb716c9-4bcf-4b36-8a03-fc8223707fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Storage Accounting Key (defined in Azure Key Vault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fde846c4-7e0a-4dd7-98f2-55b33e3dbb1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30d76db8-5222-452e-9f50-8c17d5f25338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mounting containers and directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc2adc68-35ab-4069-8d0e-8c2692e73117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c9a6dce-238b-4c42-93a3-36ba58873cf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9734bd7b-500e-4ba1-b81f-da6e4b95f39a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mount_point = \"/mnt/storageforretail/container\"\n",
    "\n",
    "\n",
    "if dbutils.fs.ls(mount_point):\n",
    "    print('OK: container')\n",
    "\n",
    "else:    \n",
    "    # Mount the container in Databricks\n",
    "    dbutils.fs.mount(\n",
    "        source = \"wasbs://container@storageforretail.blob.core.windows.net\",\n",
    "        mount_point = mount_point,\n",
    "        extra_configs = {\"fs.azure.account.key.storageforretail.blob.core.windows.net\": storage_account_key}\n",
    "    )\n",
    "    print('OK: container')\n",
    "\n",
    "# Create directories\n",
    "if dbutils.fs.ls(mount_point):\n",
    "    print('OK: container/bronze')\n",
    "else:\n",
    "    dbutils.fs.mkdirs(f\"{mount_point}/bronze\")\n",
    "    print('OK: container/bronze')\n",
    "\n",
    "if dbutils.fs.ls(mount_point):\n",
    "    print('OK: container/silver')\n",
    "else:\n",
    "    dbutils.fs.mkdirs(f\"{mount_point}/silver\")\n",
    "    print('OK: container/silver')\n",
    "\n",
    "if dbutils.fs.ls(mount_point):\n",
    "    print('OK: container/gold')\n",
    "else:\n",
    "    dbutils.fs.mkdirs(f\"{mount_point}/gold\")\n",
    "    print('OK: retailcontainer/gold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6522f737-5bbf-4608-91b2-4a0c4650008d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creating database for bronze, silver and gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f34468c-a503-44cf-ae95-860fca4a7012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze LOCATION '/mnt/databricksretail/retailcontainer/bronze'\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS silver LOCATION '/mnt/databricksretail/retailcontainer/silver'\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold LOCATION '/mnt/databricksretail/retailcontainer/gold'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ad3c483-2652-4665-9df5-9a1f0a17611a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check the IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa5aaf3-8733-4ba0-9cd5-418a585592e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "ip = requests.get(\"https://ifconfig.me\").text\n",
    "print(f\"O IP público do Databricks é: {ip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2929b2f-93de-4559-96e8-30d59fd15080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check connection to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53464495-a744-4e48-917d-122d60027484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Define the JDBC URL and authentication credentials\n",
    "properties = {\n",
    "    \"user\": sql_db_retail_user,        # Replace with your username\n",
    "    \"password\": sql_db_retail_key,      # Replace with your password\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "# Try to access the table to validate the connection\n",
    "try:\n",
    "    df = spark.read.jdbc(url=sql_db_retail_url, table=\"INFORMATION_SCHEMA.TABLES\", properties=properties)\n",
    "    df.show()  # Displays the tables in the database\n",
    "except Exception as e:\n",
    "    print(\"Connection error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a59c46b-e4fa-411c-a520-9d39b471d735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creating tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b94074df-4c2b-4be9-b9fc-47c1ae4ffd09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0e3d475-622a-4847-90a7-bad40917d817",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Declaring the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b268349-82f5-4108-a706-bb3d0dab82d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a67876af-efee-442d-a171-fbca977114a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary with tables and their primary keys\n",
    "primary_keys = {\n",
    "    \"CUSTOMERS\": [\"CUSTOMER_ID\"],\n",
    "    \"BRANDS\": [\"BRAND_ID\"],\n",
    "    \"CATEGORIES\": [\"CATEGORY_ID\"],\n",
    "    \"PRODUCTS\": [\"PRODUCT_ID\"],\n",
    "    \"STORES\": [\"STORE_ID\"],\n",
    "    \"PROMOTIONS\": [\"PROMOTION_ID\"],\n",
    "    \"PAYMENT_METHODS\": [\"PAYMENT_METHOD_ID\"],\n",
    "    \"INVENTORY\": [\"INVENTORY_ID\"],\n",
    "    \"SALES\": [\"SALE_ID\"],\n",
    "    \"TRANSACTION_ITEM\": [\"TRANSACTION_ID\"] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea722f5d-a8ef-416b-ae0c-374dcdaadd34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creating tables for the first time only\n",
    "for table in primary_keys:\n",
    "    # Get the list of primary keys for the current table\n",
    "    keys = primary_keys[table]\n",
    "\n",
    "    # Convert the list of primary keys into a SQL column definition\n",
    "    primary_keys_str = \",\\n  \".join([f\"{key} INTEGER\" for key in keys]) # DEALING WITH COMPOSITE KEYS\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS bronze.{table}\")\n",
    "\n",
    "    # Generate and execute the SQL statement\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE TABLE bronze.{table} (\n",
    "            {primary_keys_str},\n",
    "            hash STRING,\n",
    "            `load_timestamp` TIMESTAMP,\n",
    "            `end_timestamp` TIMESTAMP,\n",
    "            state INTEGER\n",
    "        ) USING DELTA\n",
    "    \"\"\")\n",
    "    print(f\"Table bronze.{table} created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "203e9a05-457e-4478-a94e-05c0ca8d8661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary with tables and their primary keys\n",
    "primary_keys = {\n",
    "    \"CUSTOMERS\": [\"CUSTOMER_ID\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16c8e3ae-1499-423a-99bb-ca51ced7c0af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ingestion on bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3210e6-5d6a-4682-851f-acf1a39392a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for table in primary_keys:\n",
    "    # Get the list of primary keys for the current table\n",
    "    keys = primary_keys[table]\n",
    "\n",
    "    # Convert the list of primary keys into a SQL column definition\n",
    "    primary_keys_str = \",\\n  \".join([f\"{key} INTEGER\" for key in keys]) # DEALING WITH COMPOSITE KEYS (just integers)\n",
    "\n",
    "    # Build condition for merge\n",
    "    merge_condition = \" AND \".join([f\"target.{key} = source.{key}\" for key in keys])\n",
    "\n",
    "\n",
    "    df_source = spark.read \\\n",
    "        .jdbc(\n",
    "            url=sql_db_retail_url,\n",
    "            table=f\"dbo.{table}\",\n",
    "            properties=properties)\n",
    "\n",
    "    # Add basics collumns to the source DataFrame:\n",
    "    df_source = df_source.withColumn(\"hash\", sha2(concat_ws(\"|\", *[col(c) for c in df_source.columns if c != \"timestamp\"]), 256))\n",
    "    df_source = df_source.withColumn(\"load_timestamp\", current_timestamp())\n",
    "    df_source = df_source.withColumn(\"end_timestamp\", lit(None).cast(\"timestamp\"))\n",
    "    df_source = df_source.withColumn(\"state\", lit(2))\n",
    "    df_source.createOrReplaceTempView(\"BRONZE_VIEW\")\n",
    "\n",
    "    df_bronze = DeltaTable.forName(spark, f\"bronze.{table}\")\n",
    "\n",
    "    # Merge!!!\n",
    "    spark.sql(f\"\"\"\n",
    "            MERGE INTO bronze.{table} AS target\n",
    "            USING BRONZE_VIEW AS source\n",
    "            ON {merge_condition}\n",
    "            WHEN MATCHED AND target.hash != source.hash AND target.state IN (2, 4) THEN\n",
    "                UPDATE SET\n",
    "                    target.state = 3,\n",
    "                    target.end_timestamp = current_timestamp()\n",
    "            WHEN NOT MATCHED BY SOURCE THEN\n",
    "                UPDATE SET\n",
    "                    target.state = 1,\n",
    "                    target.end_timestamp = current_timestamp()\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "    # Convert DeltaTable to DataFrame and filter out the updated (before) records to write to the bronze table\n",
    "\n",
    "    # mark the records that were updated (after):\n",
    "    df_source = df_source.withColumn(\"state\", lit(4))\n",
    "\n",
    "    # filtering df_source to the records that were updated (after)\n",
    "    new_records_df_4 = df_source.join(\n",
    "        df_bronze.toDF().filter(col(\"state\") == 3).select(f\"{ ' AND target.'.join(keys) }\"),  \n",
    "        on=f\"{ ' AND target.'.join(keys) }\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    df_source = df_source.withColumn(\"state\", lit(2))\n",
    "\n",
    "    new_records_df_2 = df_source.join(\n",
    "        df_bronze.toDF().filter(col(\"state\")  3).select(f\"{ ' AND target.'.join(keys) }\"),  \n",
    "        on=f\"{ ' AND target.'.join(keys) }\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Write the updated (after) records to the bronze table\n",
    "    new_records_df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"bronze.{table}\")\n",
    "    \n",
    "    print(f\"Table bronze.{table} updated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5292f91-50fe-4713-ae6e-383b4a68a309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col, concat_ws, sha2, lit\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e84dab3-3399-41fd-bf01-87dd692a4bc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for table in primary_keys:\n",
    "    # Get the list of primary keys for the current table\n",
    "    keys = primary_keys[table]\n",
    "\n",
    "    # Convert the list of primary keys into a SQL column definition\n",
    "    primary_keys_str = \",\\n  \".join([f\"{key} INTEGER\" for key in keys]) # DEALING WITH COMPOSITE KEYS (just integers)\n",
    "    merge_condition = \" AND \".join([f\"target.{key} = source.{key}\" for key in keys])\n",
    "    ids = \", \".join([f\"{key}\" for key in keys])\n",
    "\n",
    "    # Build condition for merge\n",
    "    merge_condition = \" AND \".join([f\"target.{key} = source.{key}\" for key in keys])\n",
    "\n",
    "    # taking the bronze table inside delta lake\n",
    "    df_bronze = DeltaTable.forName(spark, f\"bronze.{table}\")\n",
    "\n",
    "    # reading the source table\n",
    "    df_source = spark.read \\\n",
    "        .jdbc(\n",
    "            url=sql_db_retail_url,\n",
    "            table=f\"dbo.{table}\",\n",
    "            properties=properties)\n",
    "\n",
    "    # Add basics collumns to the source DataFrame:\n",
    "    df_source = df_source.withColumn(\"hash\", sha2(concat_ws(\"|\", *[col(c) for c in df_source.columns if c != \"timestamp\"]), 256))\n",
    "    df_source = df_source.withColumn(\"load_timestamp\", current_timestamp())\n",
    "    df_source = df_source.withColumn(\"end_timestamp\", lit(None).cast(\"timestamp\"))   \n",
    "\n",
    "    # Mark 1 for delete and 3 for update (before image) in bronze.table\n",
    "    df_bronze.alias(\"target\").merge(\n",
    "        df_source.alias(\"source\"),\n",
    "        merge_condition\n",
    "    ).whenMatchedUpdate(\n",
    "        condition=\"target.hash != source.hash AND target.state in (2,4)\",\n",
    "        set={\n",
    "            \"state\": \"3\",\n",
    "            \"end_timestamp\": current_timestamp()\n",
    "        }\n",
    "    ).whenNotMatchedBySourceUpdate(\n",
    "        set={\n",
    "            \"state\": \"1\",\n",
    "            \"end_timestamp\": current_timestamp()\n",
    "        }\n",
    "    ).execute()\n",
    "\n",
    "    # Filter rows of df_bronze wich state is 3 (update before image):\n",
    "    df_bronze_filtered3 = df_bronze.toDF().filter(col(\"state\") == 3)\n",
    "\n",
    "    # Now, using the filtered bronze rows to mark new records to state = 4 (updated after  image):\n",
    "    new_records_df4 = df_source \\\n",
    "        .withColumn(\"state\", lit(4)) \\\n",
    "        .join(\n",
    "            df_bronze_filtered3.select(f\"{ ' AND target.'.join(keys) }\"),  \n",
    "            on=f\"{ ' AND target.'.join(keys) }\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "    # Filter all rows that is not delete\n",
    "    df_bronze_filtered234 = df_bronze.toDF().filter(col(\"state\").isin(2, 3, 4))\n",
    "\n",
    "    # Now, using the filtered bronze rows to mark new records to state = 2 (insert):\n",
    "    new_records_df2 = df_source \\\n",
    "        .withColumn(\"state\", lit(2)) \\\n",
    "        .join(\n",
    "            df_bronze_filtered234.select(f\"{ ' AND target.'.join(keys) }\"),  \n",
    "            on=f\"{ ' AND target.'.join(keys) }\",\n",
    "            how=\"left_anti\"                                                 \n",
    "        )\n",
    "    \n",
    "    new_records_df = new_records_df2.union(new_records_df4)\n",
    "\n",
    "    # Write the updated (after) records to the bronze table\n",
    "    new_records_df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"bronze.{table}\")\n",
    "    \n",
    "    print(f\"Table bronze.{table} updated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11051c27-d2e4-45dc-a671-1368e3a50bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from bronze.customers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d1d7841-c86a-4cc2-b492-7dfe0d6e7ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from bronze.customers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8568808-c267-408c-8dfb-5ebc302bc42d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Schemas of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "531711fb-d939-479f-8958-4699cf2e6dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7983d1f7-46d6-4d3c-80c9-056a17276dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary with tables and their primary keys\n",
    "primary_keys = {\n",
    "    \"CUSTOMERS\": [\"CUSTOMER_ID\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04167f9e-ebba-439a-b938-3d7779c26021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for table in primary_keys:\n",
    "\n",
    "  # taking the bronze table inside delta lake\n",
    "  df = DeltaTable.forName(spark, f\"bronze.{table}\")\n",
    "  \n",
    "  # Pegando o schema original da tabela Bronze\n",
    "  schema = df.toDF().schema\n",
    "  \n",
    "  # Removendo o metadata de cada StructField\n",
    "  updated_fields = []\n",
    "  for field in schema.fields:\n",
    "      # Cria um novo StructField sem o campo metadata\n",
    "      updated_field = StructField(field.name, field.dataType, field.nullable)\n",
    "      updated_fields.append(updated_field)\n",
    "  \n",
    "  # Criando o novo schema sem o metadata\n",
    "  updated_schema = StructType(updated_fields)\n",
    "  \n",
    "  # Convertendo o novo schema para JSON\n",
    "  schema_json = json.dumps(updated_schema.jsonValue(), indent=2)\n",
    "\n",
    "  # Caminho no DBFS\n",
    "  path = f\"{mount_point}/bronze/schema_{table}.json\"\n",
    "\n",
    "  # Salvando o JSON\n",
    "  dbutils.fs.put(path, schema_json, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80adac47-c94f-4bc8-9428-73f301a43be8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(json.loads(schema_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e9dbad1-73c9-4e6f-930b-2f54d7599fc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lendo o arquivo JSON\n",
    "schema_json = dbutils.fs.head(path)\n",
    "schema_dict = json.loads(schema_json)\n",
    "\n",
    "# Extraindo os nomes das colunas do schema\n",
    "expected_columns = [field[\"name\"] for field in schema_dict[\"fields\"]]\n",
    "\n",
    "print(expected_columns)  # ['col_from_schema1', 'col_from_schema2', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d582877-41e2-46fe-a72f-0fca0cd55583",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver\n",
    "* Join\n",
    "* Schema enforcement\n",
    "* Data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72d3fbf4-8d47-48e4-b6fe-43d926894f46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81d76e39-4cfc-4134-a3f6-7b75a6071420",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Reading just active field (enforcing the schemas)\n",
    "-- Reading exactly the expected field\n",
    "-- Treating NULL\n",
    "\n",
    "CREATE OR REPLACE TABLE silver.customers USING DELTA AS\n",
    "SELECT \n",
    "    CUSTOMER_ID,\n",
    "    hash,\n",
    "    load_timestamp,\n",
    "    end_timestamp,\n",
    "    Social_Security_Number,\n",
    "    COALESCE(Name, 'NOT INFORMED') AS Name,\n",
    "    COALESCE(Email, 'NOT INFORMED') AS Email,\n",
    "    CAST(COALESCE(REGEXP_REPLACE(Phone, '[^0-9]', ''), '-1') AS BIGINT) AS Phone,\n",
    "    COALESCE(Address, 'NOT INFORMED') AS Address,\n",
    "    CAST(REGEXP_REPLACE(COALESCE(Zip_Code, '-1'), '[^0-9]', '') AS INT) AS Zip_Code\n",
    "FROM bronze.customers\n",
    "-- WHERE {processing_date} BETWEEN load_timestamp AND end_timestamp\n",
    "WHERE state in (2, 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aff65264-4935-47e4-be4d-c7876ba5d82d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Antes: criar tabela gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71dfc3e3-a30d-4d74-b3ad-b14938fdd58e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "658be3e3-0fc8-459d-bab8-c7831b2cc7bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1e38102f-ee06-4713-91e2-e0a787decbed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from bronze.customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45167fdd-6057-425b-aa57-81dd9cef220c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "230dbd58-2899-48d2-b134-1a3398e8021d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Customer\n",
    "\n",
    "* SDC2 Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae59fe4b-0af7-48d2-b0ac-57e291732554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE gold.customers (\n",
    "  SK_CUSTOMER BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "  CUSTOMER_ID INTEGER,\n",
    "  ACTIVE BOOLEAN,\n",
    "  load_timestamp TIMESTAMP,\n",
    "  end_timestamp TIMESTAMP,\n",
    "  HASH STRING,\n",
    "  SOCIAL_SECURITY_NUMBER STRING,\n",
    "  NAME STRING,\n",
    "  EMAIL STRING,\n",
    "  PHONE BIGINT,\n",
    "  ADDRESS STRING,\n",
    "  ZIP_CODE INTEGER\n",
    ")\n",
    "USING DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6484f6-8933-43c6-88ee-9d41a8e5e8dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM gold.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d71cf39-e45e-4788-9cb5-5616583a601c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reading silver and gold tables\n",
    "df_silver = DeltaTable.forName(spark, \"silver.Customers\").toDF()\n",
    "df_gold = DeltaTable.forName(spark, \"gold.Customers\")\n",
    "\n",
    "# Mark 1 for delete and 3 for update (before image) in silver.table\n",
    "df_gold.alias(\"target\").merge(\n",
    "    df_silver.alias(\"source\"),\n",
    "    \"target.CUSTOMER_ID == source.CUSTOMER_ID AND target.active == 1\"\n",
    ").whenMatchedUpdate(\n",
    "    condition=\"target.hash != source.hash\",\n",
    "    set={\n",
    "        \"active\": \"0\",\n",
    "        \"end_timestamp\": current_timestamp()\n",
    "    }\n",
    ").whenNotMatchedBySourceUpdate(\n",
    "    set={\n",
    "        \"active\": \"0\",\n",
    "        \"end_timestamp\": current_timestamp()\n",
    "    }\n",
    ").execute()\n",
    "\n",
    "# Insert Updated records to gold table\n",
    "df_gold.alias(\"target\").merge(\n",
    "    df_silver.alias(\"source\"),\n",
    "    \"target.CUSTOMER_ID == source.CUSTOMER_ID AND target.active == 1\"\n",
    ").whenNotMatchedInsert(\n",
    "    values = {\n",
    "        \"CUSTOMER_ID\": \"source.CUSTOMER_ID\",\n",
    "        \"hash\": \"source.hash\",\n",
    "        \"load_timestamp\": \"source.load_timestamp\",\n",
    "        \"end_timestamp\": \"source.end_timestamp\",\n",
    "        \"active\": \"1\",\n",
    "        \"Social_Security_Number\": \"source.Social_Security_Number\",\n",
    "        \"Name\": \"source.Name\",\n",
    "        \"Email\": \"source.Email\",\n",
    "        \"Phone\": \"source.Phone\",\n",
    "        \"Address\": \"source.Address\",\n",
    "        \"Zip_Code\": \"source.Zip_Code\"\n",
    "        }\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3b917a2-a1e1-4be0-8899-a6a73a5c9a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65632d03-c9dd-4ed0-87d4-69d7c829c43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Read from bronze.Customers just the active records\n",
    "# 2. No need for joins (it is a simple example)\n",
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dda9bab6-84d3-41ca-be81-13e29ef8f95e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS bronze.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "810c1f29-13a2-4c16-9156-29ab0280def7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Listar todas as tabelas no Hive Metastore\n",
    "tables = [\n",
    "    \"CUSTOMERS\", \"BRANDS\", \"CATEGORIES\", \"PRODUCTS\", \"STORES\",\n",
    "    \"PROMOTIONS\", \"PAYMENT_METHODS\", \"INVENTORY\", \"SALES\", \"TRANSACTION_ITEM\"\n",
    "]\n",
    "\n",
    "# Excluir todas as tabelas\n",
    "for table in tables:\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS bronze.{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f5150c-5042-4290-86c3-8dd0e9cd642a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delete all files and directories\n",
    "\n",
    "\n",
    "dbutils.fs.unmount(\"/mnt/databricksretail/retailcontainer\")\n",
    "dbutils.fs.rm(\"/mnt/databricksretail\", recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63a3a6ea-cc56-44d9-90be-af7110db339b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Excluir o banco de dados, incluindo todas as tabelas (opção CASCADE)\n",
    "spark.sql(\"DROP DATABASE bronze CASCADE\")\n",
    "spark.sql(\"DROP DATABASE silver CASCADE\")\n",
    "spark.sql(\"DROP DATABASE gold CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2d12a8-32f7-4b53-a768-fd638094cc1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Select * from bronze.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0c90e97-fd8a-4cb1-8a81-215e4fa92d4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Select * from SILVER.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a43973ac-c1c9-4116-a069-eb74be184548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Select * from GOLD.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eeda0e14-1edb-45d7-af97-0b86c93f0eea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for gold:\n",
    "\n",
    "# Deduplicate the source DataFrame\n",
    "window_spec = Window.partitionBy(\"CUSTOMER_ID\").orderBy(col(\"load_timestamp\").desc())\n",
    "df_silver_dedup = df_silver.withColumn(\"row_num\", row_number().over(window_spec)).filter(col(\"row_num\") == 1).drop(\"row_num\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1428101144523825,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Basic configuration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
